# Prepare sample sheet for demultiplexing. 

# The sample sheet generated by Clarity LIMS is not compatible with
# bcl2fastq2. This script adds two headers to the sample sheet to make
# it readable by bcl2fastq2.

# Sample sheet management:
#  * LIMS mode *
#  - This script takes the sample sheet from the "Input sample sheet" ResultFile 
#    object associated with the task's LIMS process. If there is no sample sheet, 
#    it takes it from the cluster generation process. If
#    no clustering process is found, it takes it from <run folder>/SampleSheet.csv
#  - It stores the *input* sample sheet in the LIMS process if it was fetched from
#    somewhere else, but this is not used further.
#  - It adds the headers and copies it to the process in the LIMS, on the 
#    "Demultiplexing sample sheet" ResultFile object. 
#  - Other tasks always take the sample sheet from the LIMS process ("Demultiplexing
#    sample sheet"), but the demultiplexing process also writes it to
#    DemultiplexingSampleSheet.<process_id>.csv because bcl2fastq2 needs an on-disk copy.
#
#  * Command line mode *
#  - This script reads the sample sheet from SampleSheet.csv and writes it to
#    DemutliplexingSampleSheet.csv. The input sample sheet file may be overridden
#    with the --input-sample-sheet option.
#  - Other tasks read the sample sheet from DemultiplexingSampleSheet.csv or 
#    another file provided on the command line.

# Since this script must deal with two sample sheets, input and output, it can't
# use the "taskmgr.Task" interface, and has to manually I/O the sample sheets.

import os.path, sys
import argparse
import subprocess
import datetime
import re

#from Bio.Seq import Seq

from genologics.lims import *
from common import nsc, utilities, taskmgr

TASK_NAME = "20. Prepare SampleSheet"
TASK_DESCRIPTION = "Prepare sample sheet for bcl2fastq2"
TASK_ARGS = ['work_dir', 'lanes']


def main(task):
    """Sample sheet processing."""

    task.add_argument(
            '--input-sample-sheet',
            default=None, # would use work-dir/SampleSheet.csv but dont know work-dir
            help="Path to source sample sheet to transform"
            )
    task.add_argument(
            '--output-sample-sheet',
            default=None,
            help="Path to destination sample sheet to write"
            )
    task.running()

    # Flag to track if the sample sheet was found right on the current LIMS process
    # If the sample sheet was found on the current process, there is no need to 
    # re-upload it.
    found_on_process = False
    sample_sheet = None
    sample_sheet_lims_artifact = None # For use when uploading the input sample sheet
    if task.process:
        # Try to get the input sample sheet:
        
        # On the current LIMS process
        for o in task.process.all_outputs(unique=True):
            if o.output_type == "ResultFile" and o.name == nsc.INPUT_SAMPLE_SHEET:
                sample_sheet_lims_artifact = o
                if len(o.files) == 1:
                    sample_sheet = o.files[0].download()
                    found_on_process = True


        # From a file (fall through to non-LIMS case)
        if not sample_sheet:
            sample_sheet_path = os.path.join(task.work_dir, "SampleSheet.csv")

    else:
        sample_sheet_path = task.args.input_sample_sheet
        if not sample_sheet_path:
            sample_sheet_path = os.path.join(task.work_dir, "SampleSheet.csv")
            if not os.path.exists(sample_sheet_path):
                sample_sheet_path = os.path.join(task.bc_dir, "SampleSheet.csv")
        

    # If not using LIMS, or if LIMS sources failed, try to get a file
    if not sample_sheet:
        try:
            sample_sheet = open(sample_sheet_path, 'rb').read()
        except IOError:
            task.fail("Couldn't find the sample sheet")

    # Upload the input sample sheet as a record if -using LIMS, -it wasn't there already
    if task.process and not found_on_process:
        utilities.upload_file(
                task.process,
                name = nsc.INPUT_SAMPLE_SHEET,
                path = "SampleSheet.csv",
                data = sample_sheet
                )

    # Always replace special characters with ?
    sample_sheet = replace_special_chars(sample_sheet)

    # Doctor the sample sheet, only if using HiSeq and it doesn't have [Data] header
    instrument = utilities.get_instrument_by_runid(task.run_id)
    if instrument.startswith("hiseq") and not re.search(r"\[Data\]", sample_sheet):
        sample_sheet = convert_from_bcl2fastqv1(sample_sheet)
    if instrument == "hiseqx":
        sample_sheet = clear_index2_column(sample_sheet)

    # Post the result, as appropriate...
    if task.process:
        utilities.upload_file(
                task.process,
                name = nsc.SAMPLE_SHEET,
                path = "DemultiplexingSampleSheet.csv",
                data = sample_sheet
                )
    else:
        if task.args.output_sample_sheet:
            path = os.path.join(task.work_dir, task.args.output_sample_sheet)
        else:
            path = os.path.join(task.work_dir, "DemultiplexingSampleSheet.csv")

        open(path, 'wb').write(sample_sheet)
    
    task.success_finish()


def replace_special_chars(sample_sheet_data):
    return "".join(c if ord(c) < 128 else '?' for c in sample_sheet_data)


def rev_comp(sequence):
    COMPLEMENTARY = {'A':'T', 'T':'A', 'G':'C', 'C':'G'}
    return "".join(COMPLEMENTARY[b] for b in reversed(sequence))


def clear_index2_column(original_data):
    lines = original_data.splitlines()
    output_rows = []
    data = False
    header = False
    index2index = 0
    for l in lines:
        line = l.strip("\r\n")
        if not data and line.lower().startswith("[data]"):
            data = True
        elif data:
            if not header:
                header = line.strip().lower().split(",")
                try:
                    index2index = header.index("index2")
                except ValueError:
                    return original_data
            else:
                parts = line.split(",")
                if len(parts) > index2index:
                    parts[index2index] = ""
                line = ",".join(parts)
        output_rows.append(line)

    return "\r\n".join(output_rows)


def convert_from_bcl2fastqv1(original_data):
    main_headers = "[Settings]\r\n[Data]\r\n"
    data = [l.strip("\r\n").split(",") for l in original_data.splitlines()]

    replacements = {
            "sampleid": "Sample_Name",
            "description": "Sample_ID",
            "sampleproject": "Sample_Project"
            }


    # Index of Description column:
    description_index = next(i for i, c in enumerate(data[0]) if c.lower() == "description")
    any_empty_description = any(r[description_index] == "" for r in data[1:])
    if any_empty_description:
        del replacements["description"]
        replacements["sampleid"] = "Sample_ID"

    # Replace column names, get index (numeric offset) of the "Index" column
    index_column_index = None
    sample_id_index = None
    for i, cell in enumerate(data[0]):
        rep = replacements.get(cell.lower())
        if rep:
            data[0][i] = rep

        if cell.lower() == "index":
            index_column_index = i
        if cell.lower() == "sampleid":
            sample_id_index = i


    # Add the Sample_Name column if "Description" can't be used as Sample_ID
    # The we use SampleID as sample name and sample ID
    if any_empty_description:
        data[0].append("Sample_Name")
        for r in data[1:]:
            r.append(r[sample_id_index])


    # Split the index into first and second part
    use_dual_index = any(row[index_column_index].find("-") != -1 for row in data[1:])
    if use_dual_index:
        data[0].insert(index_column_index+1, "index2")
        for row in data[1:]:
            indexes = row[index_column_index].split("-")
            if len(indexes) == 1:
                indexes.append("")
                if indexes[0] == "NoIndex":
                    indexes[0] = ""
            row[index_column_index] = indexes[0]
            row.insert(index_column_index+1, indexes[1])
    else:
        for row in data[1:]:
            if row[index_column_index] == "NoIndex":
                row[index_column_index] = ""

    return main_headers + "\r\n".join(
            [",".join(cells) for cells in data]
            )
    


with taskmgr.Task(TASK_NAME, TASK_DESCRIPTION, TASK_ARGS) as task:
    main(task)

