# Prepare sample sheet for demultiplexing. 

# The sample sheet generated by Clarity LIMS is not compatible with
# bcl2fastq2. This script adds two headers to the sample sheet to make
# it readable by bcl2fastq2.

# Sample sheet management:
#  * LIMS mode *
#  - This script takes the sample sheet from the "Input sample sheet" ResultFile 
#    object associated with the task's LIMS process. If there is no sample sheet, 
#    it takes it from the cluster generation process. If
#    no clustering process is found, it takes it from <run folder>/SampleSheet.csv
#  - It stores the *input* sample sheet in the LIMS process if it was fetched from
#    somewhere else, but this is not used further.
#  - It adds the headers and copies it to the process in the LIMS, on the 
#    "Demultiplexing sample sheet" ResultFile object. 
#  - Other tasks always take the sample sheet from the LIMS process ("Demultiplexing
#    sample sheet"), but the demultiplexing process also writes it to
#    DemultiplexingSampleSheet.<process_id>.csv because bcl2fastq2 needs an on-disk copy.
#
#  * Command line mode *
#  - This script reads the sample sheet from SampleSheet.csv and writes it to
#    DemutliplexingSampleSheet.csv. The input sample sheet file may be overridden
#    with the --input-sample-sheet option.
#  - Other tasks read the sample sheet from DemultiplexingSampleSheet.csv or 
#    another file provided on the command line.

# Since this script must deal with two sample sheets, input and output, it can't
# use the "taskmgr.Task" interface, and has to manually I/O the sample sheets.

import os.path, sys
import argparse
import subprocess
import datetime

#from Bio.Seq import Seq

from genologics.lims import *
from common import nsc, utilities, slurm, taskmgr

TASK_NAME = "Prepare SampleSheet"
TASK_DESCRIPTION = "Prepare sample sheet for bcl2fastq2"
TASK_ARGS = ['work_dir']


def main(task):
    """Sample sheet processing."""

    task.add_argument(
            '--input-sample-sheet',
            default=None, # would use work-dir/SampleSheet.csv but dont know work-dir
            help="Path to source sample sheet to transform"
            )
    task.add_argument(
            '--output-sample-sheet',
            default=None,
            help="Path to destination sample sheet to write"
            )
    task.running()

    # Flag to track if the sample sheet was found right on the current LIMS process
    # If the sample sheet was found on the current process, there is no need to 
    # re-upload it.
    found_on_process = False
    sample_sheet = None
    sample_sheet_lims_artifact = None # For use when uploading the input sample sheet
    if task.process:
        # Try to get the input sample sheet:
        
        # On the current LIMS process
        for o in task.process.all_outputs(unique=True):
            if o.output_type == "ResultFile" and o.name == nsc.INPUT_SAMPLE_SHEET:
                sample_sheet_lims_artifact = o
                if len(o.files) == 1:
                    sample_sheet = o.files[0].download()
                    found_on_process = True

        # From the clustering process
        if not sample_sheet:
            sample_sheet = get_ss_from_cluster_proc(task.process)

        # From a file (fall through to non-LIMS case)
        if not sample_sheet:
            sample_sheet_path = os.path.join(task.work_dir, "SampleSheet.csv")

    else:
        sample_sheet_path = task.args.input_sample_sheet
        if not sample_sheet_path:
            sample_sheet_path = os.path.join(task.work_dir, "SampleSheet.csv")
        

    # If not using LIMS, or if LIMS sources failed, try to get a file
    if not sample_sheet:
        try:
            sample_sheet = open(sample_sheet_path, 'rb').read()
        except IOError:
            task.fail("Couldn't find the sample sheet")

    # Upload the input sample sheet as a record if -using LIMS, -it wasn't there already
    if task.process and not found_on_process:
        utilities.upload_file(
                task.process,
                name = nsc.INPUT_SAMPLE_SHEET,
                path = "SampleSheet.csv",
                data = sample_sheet
                )

    # Doctor the sample sheet, only if using HiSeq and it doesn't have [Data] header
    instrument = utilities.get_instrument_by_runid(task.run_id)
    if instrument == "hiseq" and sample_sheet.find("\r\n[Data]\r\n") == -1:
        sample_sheet = convert_from_bcl2fastqv1(sample_sheet)

    # Invert the read2 indexes
    if instrument == "nextseq":
        sample_sheet = reverse_complement_index2(sample_sheet)
    
    # Post the result, as appropriate...
    if task.process:
        utilities.upload_file(
                task.process,
                name = nsc.SAMPLE_SHEET,
                path = "DemultiplexingSampleSheet.csv",
                data = sample_sheet
                )
    else:
        if task.args.output_sample_sheet:
            path = os.path.join(task.work_dir, task.args.output_sample_sheet)
        else:
            path = os.path.join(task.work_dir, "DemultiplexingSampleSheet.csv")

        open(path, 'wb').write(sample_sheet)
    
    task.success_finish()


def get_ss_from_cluster_proc(process):
    # On the associated cluster generation process
    parent_processes = process.parent_processes()
    parent_pids = set(p.id for p in parent_processes)

    # Flow cell ID
    fcid = process.all_inputs()[0].location[0].name

    # This script can only handle the case when there is a single clustering process
    if len(parent_pids) == 1:
        cluster_proc = parent_processes[0]
        outputs = cluster_proc.all_outputs(unique=True)
        for io in cluster_proc.input_output_maps:
            i = io[0]
            o = io[1]
            if o['output-type'] == 'ResultFile' and\
                    o['output-generation-type'] == 'PerAllInputs':
                if o['uri'].name == 'SampleSheet csv':
                    if len(o['uri'].files) == 1:
                        data = o['uri'].files[0].download()
                        lines = data.splitlines()
                        # Warning: this assumes the old style sample sheet
                        # (bcl2fastq 1.84). Will probably be changing in 
                        # mid 2016 or so
                        if len(lines) >= 2 and lines[1].startswith(fcid+","):
                            return data

    return None


def rev_comp(sequence):
    COMPLEMENTARY = {'A':'T', 'T':'A', 'G':'C', 'C':'G'}
    return [COMPLEMENTARY[b] for b in reversed(sequence)]


def reverse_complement_index2(original_data):
    original_lines = [l.strip("\r\n") for l in original_data.splitlines()]
    data_start = next(i for i, d in enumerate(original_lines) if d == "[Data]")
    data = [l.split(",") for l in original_lines[data_start+1:] if l.strip() != ""]
    try:
        index2_col = next(i for i, c in enumerate(data[0]) if c.lower() == "index2")
        for row in data[1:]:
            #row[index2_col] = str(Seq(row[index2_col]).reverse_complement())
            row[index2_col] = rev_comp(row[index2_col])

        return "\r\n".join(
                original_lines[0:data_start+1] +\
                [",".join(cells) for cells in data]
                )
    except StopIteration: # index2 column not found
        return original_data


def convert_from_bcl2fastqv1(original_data):
    main_headers = "[Settings]\r\n[Data]\r\n"
    data = [l.strip("\r\n").split(",") for l in original_data.splitlines()]

    replacements = {
            "sampleid": "Sample_Name",
            "description": "Sample_ID",
            "sampleproject": "Sample_Project"
            }


    # Index of Description column:
    description_index = next(i for i, c in enumerate(data[0]) if c.lower() == "description")
    any_empty_description = any(r[description_index] == "" for r in data[1:])
    if any_empty_description:
        del replacements["description"]
        replacements["sampleid"] = "Sample_ID"

    # Replace column names, get index (numeric offset) of the "Index" column
    index_column_index = None
    sample_id_index = None
    for i, cell in enumerate(data[0]):
        rep = replacements.get(cell.lower())
        if rep:
            data[0][i] = rep

        if cell.lower() == "index":
            index_column_index = i
        if cell.lower() == "sampleid":
            sample_id_index = i


    # Add the Sample_Name column if "Description" can't be used as Sample_ID
    # The we use SampleID as sample name and sample ID
    data[0].append("Sample_Name")
    for r in data[1:]:
        r.append(r[sample_id_index])


    # Split the index into first and second part
    use_dual_index = any(row[index_column_index].find("-") != -1 for row in data[1:])
    if use_dual_index:
        data[0].insert(index_column_index+1, "index2")
        for row in data[1:]:
            indexes = row[index_column_index].split("-")
            if len(indexes) == 1:
                indexes.append("")
                if indexes[0] == "NoIndex":
                    indexes[0] = ""
            row[index_column_index] = indexes[0]
            row.insert(index_column_index+1, indexes[1])

    return main_headers + "\r\n".join(
            [",".join(cells) for cells in data]
            )
    


with taskmgr.Task(TASK_NAME, TASK_DESCRIPTION, TASK_ARGS) as task:
    main(task)

